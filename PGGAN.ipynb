{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from math import log2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [1, 1, 1, 1, 1/2, 1/4, 1/8, 1/16, 1/32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernal_size=3, stride=1, padding=1, gain=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size=kernal_size, stride=stride, padding=padding)\n",
    "        self.scale = (gain/(in_channels*kernal_size**2))**0.5\n",
    "        self.bias = self.conv.bias\n",
    "        self.conv.bias = None\n",
    "\n",
    "        nn.init.normal_(self.conv.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x*self.scale)+self.bias.view(1, self.bias.shape[0], 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x/torch.sqrt(torch.mean(x**2, dim=1, keepdim=True) + self.epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pixelnorm=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = WSConv2d(in_channels, out_channels)\n",
    "        self.conv2 = WSConv2d(out_channels, out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        self.pn = PixelNorm()\n",
    "        self.use_pn = pixelnorm\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky(self.conv1(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        x = self.leaky(self.conv2(x))\n",
    "        x = self.pn(x) if self.use_pn else x\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, in_channels, img_channels=3):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            PixelNorm(),\n",
    "            nn.ConvTranspose2d(z_dim, in_channels, 4, 1, 0),\n",
    "            nn.LeakyReLU(0, 2),\n",
    "            WSConv2d(in_channels, in_channels,\n",
    "                     kernal_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm()\n",
    "        )\n",
    "        self.rgb = WSConv2d(in_channels, img_channels,\n",
    "                            kernal_size=1, stride=1, padding=0)\n",
    "        self.prog_blocks, self.rgb_layers = nn.ModuleList(), nn.ModuleList([\n",
    "            self.rgb])\n",
    "\n",
    "        for i in range(len(factors)-1):\n",
    "            conv_in_c = int(in_channels*factors[i])\n",
    "            conv_out_c = int(in_channels*factors[i+1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
    "            self.rgb_layers.append(\n",
    "                WSConv2d(conv_out_c, img_channels, kernal_size=1, stride=1, padding=0))\n",
    "\n",
    "    def fade_in(self, alpha, upscaled, generated):\n",
    "        return torch.tanh(alpha*generated+(1-alpha)*upscaled)\n",
    "\n",
    "    def forward(self, x, alpha, steps):\n",
    "        out = self.initial(x)\n",
    "\n",
    "        if steps == 0:\n",
    "            return self.rgb(out)\n",
    "        for step in range(steps):\n",
    "            upscaled = F.interpolate(out, scale_factor=2, mode=\"nearest\")\n",
    "            out = self.prog_blocks[step](upscaled)\n",
    "        final_upscaled = self.rgb_layers[steps-1](upscaled)\n",
    "        final_out = self.rgb_layers[steps](out)\n",
    "        return self.fade_in(alpha, final_upscaled, final_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, z_dim, in_channels, img_channels=3):\n",
    "        super().__init__()\n",
    "        self.prog_blocks, self.rgb_layers = nn.ModuleList(), nn.ModuleList()\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "        for i in range(len(factors)-1, 0, -1):\n",
    "            conv_in_c = int(in_channels*factors[i])\n",
    "            conv_out_c = int(in_channels*factors[i-1])\n",
    "            self.prog_blocks.append(\n",
    "                ConvBlock(conv_in_c, conv_out_c, pixelnorm=False))\n",
    "            self.rgb_layers.append(\n",
    "                WSConv2d(img_channels, conv_in_c, kernal_size=1, stride=1, padding=0))\n",
    "\n",
    "        self.initial_rgb = WSConv2d(\n",
    "            img_channels, in_channels, kernal_size=1, stride=1, padding=0)\n",
    "        self.rgb_layers.append(self.initial_rgb)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.final_block = nn.Sequential(\n",
    "            WSConv2d(in_channels+1, in_channels,\n",
    "                     kernal_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels,\n",
    "                     kernal_size=4, stride=1, padding=0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, 1, kernal_size=1, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def fade_in(self, alpha, downscale, out):\n",
    "        return alpha*out+(1-alpha)*downscale\n",
    "\n",
    "    def minibatch_std(self, x):\n",
    "        batch_stat = torch.std(x, dim=0).mean().repeat(\n",
    "            x.shape[0], 1, x.shape[2], x.shape[3])\n",
    "        return torch.cat([x, batch_stat], dim=1)\n",
    "\n",
    "    def forward(self, x, alpha, steps):\n",
    "        cur_step = len(self.prog_blocks) - steps\n",
    "        out = self.leaky(self.rgb_layers[cur_step](x))\n",
    "\n",
    "        if steps == 0:\n",
    "            out = self.minibatch_std(out)\n",
    "            return self.final_block(out).view(out.shape[0], -1)\n",
    "\n",
    "        downscaled = self.leaky(self.rgb_layers[cur_step+1](self.avg_pool(x)))\n",
    "        out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
    "        out = self.fade_in(alpha, downscaled, out)\n",
    "\n",
    "        for step in range(cur_step+1, len(self.prog_blocks)):\n",
    "            out = self.prog_blocks[step](out)\n",
    "            out = self.avg_pool(out)\n",
    "        out = self.minibatch_std(out)\n",
    "        return self.final_block(out).view(out.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK 4\n",
      "OK 8\n",
      "OK 16\n",
      "OK 32\n",
      "OK 64\n",
      "OK 128\n",
      "OK 256\n",
      "OK 512\n",
      "OK 1024\n"
     ]
    }
   ],
   "source": [
    "Z_DIM = 50\n",
    "IN_CHANNELS = 256\n",
    "gen = Generator(Z_DIM, IN_CHANNELS, img_channels=3)\n",
    "disc = Discriminator(Z_DIM, IN_CHANNELS, img_channels=3)\n",
    "\n",
    "for resolution in [4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "    num_steps = int(log2(resolution/4))\n",
    "    x = torch.randn((1, Z_DIM, 1, 1))\n",
    "    z = gen(x, 0.5, steps=num_steps)\n",
    "    assert z.shape == (1, 3, resolution, resolution)\n",
    "    out = disc(z, alpha=0.5, steps=num_steps)\n",
    "    assert out.shape == (1, 1)\n",
    "    print(\"OK\", resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmarks = True\n",
    "INIT_IMG_SIZE = 4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = [32, 32, 32, 16, 16, 16, 16, 8, 4]\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 512\n",
    "IN_CHANNELS = 512\n",
    "DISC_ITERATIONS = 1\n",
    "LAMBDA_GP = 10\n",
    "PROGAN_EPOCHS = [10]*len(BATCH_SIZE)\n",
    "FIXED_NOISE = torch.randn(8, Z_DIM, 1, 1).to(DEVICE)\n",
    "NUM_WORKERS = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME:  20230204-214046\n"
     ]
    }
   ],
   "source": [
    "print(\"TIME: \", now.strftime(\"%Y%m%d-%H%M%S\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTensorBoard(writer, loss_critic, loss_gen, real, fake, tensorboard_step):\n",
    "    writer.add_scalar(\"Loss Critic\", loss_critic, global_step=tensorboard_step)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # take out (up to) 8 examples to plot\n",
    "        img_grid_real = torchvision.utils.make_grid(real[:8], normalize=True)\n",
    "        img_grid_fake = torchvision.utils.make_grid(fake[:8], normalize=True)\n",
    "        writer.add_image(\"Real\", img_grid_real, global_step=tensorboard_step)\n",
    "        writer.add_image(\"Fake\", img_grid_fake, global_step=tensorboard_step)\n",
    "\n",
    "\n",
    "def gradient_penalty(critic, real, fake, alpha, train_step, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images, alpha, train_step)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "def get_loader(image_size):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.Normalize(\n",
    "                [0.5 for _ in range(CHANNELS_IMG)],\n",
    "                [0.5 for _ in range(CHANNELS_IMG)],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    batch_size = BATCH_SIZE[int(log2(image_size / 4))]\n",
    "    dataset = datasets.ImageFolder(root=\"./datasets/anime\", transform=transform)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return loader, dataset\n",
    "\n",
    "def trainFunc(disc,gen,loader,dataset,step,alpha,opt_disc,opt_gen,tb_step,writer,scaler_gen,scaler_disc):\n",
    "    loop=tqdm(loader,leave=True)\n",
    "    for batch_indx,(real,_) in enumerate(loop):\n",
    "        real=real.to(DEVICE)\n",
    "        cur_batch_size=real.shape[0]\n",
    "\n",
    "        noise=torch.randn(cur_batch_size,Z_DIM,1,1).to(DEVICE)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            fake=gen(noise,alpha,step)\n",
    "            critic_real=disc(real,alpha,step)\n",
    "            critic_fake=disc(fake.detach(),alpha,step)\n",
    "            gp=gradient_penalty(disc,real,fake,alpha,step,DEVICE)\n",
    "            loss_critic = (\n",
    "                -(torch.mean(critic_real)-torch.mean(critic_fake))\n",
    "                + LAMBDA_GP*gp\n",
    "                + (0.001 * torch.mean(critic_real**2))\n",
    "            )\n",
    "        opt_disc.zero_grad()\n",
    "        scaler_disc.scale(loss_critic).backward()\n",
    "        scaler_disc.step(opt_disc)\n",
    "        scaler_disc.update()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            gen_fake=disc(fake,alpha,step)\n",
    "            loss_gen=-torch.mean(gen_fake)\n",
    "        opt_gen.zero_grad()\n",
    "        scaler_gen.scale(loss_gen).backward()\n",
    "        scaler_gen.step(opt_gen)\n",
    "        scaler_gen.update()\n",
    "\n",
    "        alpha+=cur_batch_size/(len(dataset)*PROGAN_EPOCHS[step]*0.5)\n",
    "        alpha=min(alpha,1)\n",
    "\n",
    "        if batch_indx%500 ==0:\n",
    "            with torch.no_grad():\n",
    "                fixed_fakes=gen(FIXED_NOISE,alpha,step)*0.5 + 0.5\n",
    "            plotTensorBoard(\n",
    "                writer,\n",
    "                loss_critic.item(),\n",
    "                loss_gen.item(),\n",
    "                real.detach(),\n",
    "                fixed_fakes.detach(),\n",
    "                tb_step\n",
    "            )\n",
    "            tb_step+=1\n",
    "        loop.set_postfix(\n",
    "            gp=gp.item(),\n",
    "            loss_critic=loss_critic.item(),\n",
    "        )\n",
    "\n",
    "    return tb_step, alpha\n",
    "\n",
    "def train_wrapper():\n",
    "    gen=Generator(Z_DIM,IN_CHANNELS,CHANNELS_IMG).to(DEVICE)\n",
    "    disc=Discriminator(Z_DIM,IN_CHANNELS,CHANNELS_IMG).to(DEVICE)\n",
    "\n",
    "    opt_gen=optim.Adam(gen.parameters(),lr=LR,betas=(0.0,0.99))\n",
    "    opt_disc=optim.Adam(disc.parameters(),lr=LR,betas=(0.0,0.99))\n",
    "\n",
    "    scaler_disc=torch.cuda.amp.GradScaler()\n",
    "    scaler_gen=torch.cuda.amp.GradScaler()\n",
    "\n",
    "    writer=SummaryWriter(f'logs/progan/'+ now.strftime(\"%Y%m%d-%H%M%S\") + \"/\")\n",
    "\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    \n",
    "    tb_step=0\n",
    "    step=int(log2(INIT_IMG_SIZE/4))\n",
    "    for num_epochs in PROGAN_EPOCHS[step:]:\n",
    "        alpha=1e-5\n",
    "        loader,dataset = get_loader(4*2**step)\n",
    "        print(\"IMAGE SIZE\",4*2**step)\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"Range\",4*2**step) \n",
    "            tb_step,alpha=trainFunc(\n",
    "                disc,gen,loader,dataset,step,alpha,opt_disc,opt_gen,tb_step,writer,scaler_gen,scaler_disc\n",
    "            )\n",
    "        step += 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE SIZE 4\n",
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [02:34<00:00, 12.85it/s, gp=0.00758, loss_critic=0.136]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.37it/s, gp=0.00781, loss_critic=0.245]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:52<00:00, 37.67it/s, gp=0.00609, loss_critic=0.172]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.51it/s, gp=0.00804, loss_critic=0.0171]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.31it/s, gp=0.00868, loss_critic=0.232]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.48it/s, gp=0.00525, loss_critic=0.1]     \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.60it/s, gp=0.00298, loss_critic=0.14]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.43it/s, gp=0.00614, loss_critic=0.0561]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.21it/s, gp=0.00501, loss_critic=0.0895]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [00:50<00:00, 39.52it/s, gp=0.00483, loss_critic=0.102]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE SIZE 8\n",
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:35<00:00, 20.76it/s, gp=0.00242, loss_critic=0.302]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:35<00:00, 20.74it/s, gp=0.00598, loss_critic=0.0448]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:35<00:00, 20.71it/s, gp=0.0026, loss_critic=0.249]    \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:36<00:00, 20.50it/s, gp=0.00544, loss_critic=0.243]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:35<00:00, 20.71it/s, gp=0.00932, loss_critic=0.177]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:35<00:00, 20.72it/s, gp=0.00416, loss_critic=0.0667]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:36<00:00, 20.63it/s, gp=0.00457, loss_critic=-.079]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:36<00:00, 20.68it/s, gp=0.00435, loss_critic=-.0818]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:36<00:00, 20.61it/s, gp=0.00479, loss_critic=0.0393]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [01:36<00:00, 20.58it/s, gp=0.0035, loss_critic=0.0373]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE SIZE 16\n",
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [04:02<00:00,  8.20it/s, gp=0.00136, loss_critic=-.611]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [04:08<00:00,  8.00it/s, gp=0.00599, loss_critic=-.0878] \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:56<00:00,  8.41it/s, gp=0.00213, loss_critic=-.205]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:54<00:00,  8.46it/s, gp=0.00606, loss_critic=-.00322] \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:55<00:00,  8.44it/s, gp=0.0046, loss_critic=-.348]    \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:55<00:00,  8.44it/s, gp=0.0023, loss_critic=0.216]    \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:55<00:00,  8.43it/s, gp=0.00567, loss_critic=-.179]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:56<00:00,  8.42it/s, gp=0.00258, loss_critic=0.323]   \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:55<00:00,  8.44it/s, gp=0.00851, loss_critic=0.0186]  \n",
      "  0%|          | 0/1987 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987/1987 [03:55<00:00,  8.44it/s, gp=0.00426, loss_critic=0.0867]  \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE SIZE 32\n",
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3973/3973 [14:07<00:00,  4.69it/s, gp=0.00422, loss_critic=1.15]    \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3973/3973 [13:57<00:00,  4.74it/s, gp=0.00368, loss_critic=-.412]   \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3973/3973 [14:24<00:00,  4.60it/s, gp=0.00263, loss_critic=-.557]   \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3973/3973 [13:48<00:00,  4.80it/s, gp=0.00292, loss_critic=-.553]   \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3973/3973 [13:46<00:00,  4.80it/s, gp=0.00636, loss_critic=-.647]   \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3973/3973 [14:06<00:00,  4.69it/s, gp=0.00259, loss_critic=-.142]   \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3973/3973 [14:37<00:00,  4.53it/s, gp=0.00507, loss_critic=-.16]    \n",
      "  0%|          | 0/3973 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 548/3973 [02:05<13:03,  4.37it/s, gp=0.00418, loss_critic=-.149]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8776\\2033555613.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8776\\419971235.py\u001b[0m in \u001b[0;36mtrain_wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Range\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             tb_step,alpha=trainFunc(\n\u001b[0m\u001b[0;32m    133\u001b[0m                 \u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt_disc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtb_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscaler_disc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8776\\419971235.py\u001b[0m in \u001b[0;36mtrainFunc\u001b[1;34m(disc, gen, loader, dataset, step, alpha, opt_disc, opt_gen, tb_step, writer, scaler_gen, scaler_disc)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mopt_disc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mscaler_disc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_critic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mscaler_disc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_disc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mscaler_disc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_wrapper()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
