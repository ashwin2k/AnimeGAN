{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4728825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "def setup(rank, world_size):    \n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'    \n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7682a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "def prepare(rank, world_size, batch_size=32, pin_memory=False, num_workers=0):\n",
    "    transforms_img= transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((64,64)), #transforms.Resize(IMAGE_SIZE) resizes propotionally\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5 for _ in range(channels_dim)], [0.5 for _ in range(channels_dim)])\n",
    "    ]\n",
    "    )\n",
    "    dataset = datasets.ImageFolder(root=\"./datasets/anime\",transform=transforms_img)\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=pin_memory, num_workers=num_workers, drop_last=False, shuffle=False, sampler=sampler)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c829e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "912a8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,channels_inp,input_features):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.disc=nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_inp,input_features,kernel_size=4,stride=2,padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(input_features,input_features*2,4,2,1),\n",
    "            self._block(input_features*2,input_features*4,4,2,1),\n",
    "            self._block(input_features*4,input_features*8,4,2,1),\n",
    "            nn.Conv2d(input_features*8,1,kernel_size=4,stride=2,padding=0),\n",
    "            nn.Sigmoid()    \n",
    "        )\n",
    "    def _block(self,in_channels,out_channels,kernalsize,stride,padding):\n",
    "        return nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernalsize,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False\n",
    "        ),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.disc(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ae7531",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,z_dim,channels_img,input_features):\n",
    "        super(Generator,self).__init__()\n",
    "        self.net = nn.Sequential(   \n",
    "            self._block(z_dim,input_features*16,4,1,0),\n",
    "            self._block(input_features*16,input_features*8,4,2,1),\n",
    "            self._block(input_features*8,input_features*4,4,2,1),\n",
    "            self._block(input_features*4,input_features*2,4,2,1),\n",
    "            nn.ConvTranspose2d(\n",
    "                input_features*2,channels_img,kernel_size=4,stride=2,padding=1\n",
    "            ),\n",
    "            nn.Tanh()\n",
    "\n",
    "        )   \n",
    "    def _block(self,in_channels,out_channels,kernalsize,stride,padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernalsize,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "        \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0981aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,(nn.Conv2d,nn.ConvTranspose2d,nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data,0.0,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8ec0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-4\n",
    "z_dim=100\n",
    "img_size=64\n",
    "channels_dim=3\n",
    "batch_size=128\n",
    "num_epochs=50\n",
    "\n",
    "features_disc=64\n",
    "features_gen=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbac2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "def mainwrapper(rank,world_size):\n",
    "    setup(rank,world_size)\n",
    "    dataloader=prepare(rank,world_size)\n",
    "    disc=Discriminator(channels_dim,features_disc).to(rank) \n",
    "    gen=Generator(z_dim,channels_dim,features_gen).to(rank)\n",
    "    init_weights(disc)\n",
    "    init_weights(gen)\n",
    "    disc = DDP(disc, device_ids=[rank], output_device=rank, find_unused_parameters=True)\n",
    "    gen = DDP(gen, device_ids=[rank], output_device=rank, find_unused_parameters=True)\n",
    "    \n",
    "    fixed_noise=torch.randn(32,z_dim,1,1).to(DEVICE)\n",
    "    opt_disc=optim.Adam(disc.parameters(),lr=lr,betas=(0.5,0.999))    \n",
    "    opt_gen=optim.Adam(gen.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "    critereon=nn.BCELoss()\n",
    "    \n",
    "    print(\"TIME: \",now.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    writer_fake=SummaryWriter(f\"runs/DCGAN-multiGPU/fake/\"+ now.strftime(\"%Y%m%d-%H%M%S\") + \"/\")\n",
    "    writer_real=SummaryWriter(f\"runs/DCGAN-multiGPU/real/\"+ now.strftime(\"%Y%m%d-%H%M%S\") + \"/\")\n",
    "    for epoch in epochs:\n",
    "        dataloader.sampler.set_epoch(epoch)\n",
    "        for batch_index, (real,_) in enumerate(loader):\n",
    "            real=real.to(rank)\n",
    "            noise=torch.randn((batch_size,z_dim,1,1)).to(rank)\n",
    "            fake_img=gen(noise)\n",
    "            \n",
    "            disc_real=disc(real).reshape(-1)\n",
    "            lossD_real=critereon(disc_real,torch.ones_like(disc_real))\n",
    "            disc_fake=disc(fake_img).reshape(-1)\n",
    "            lossD_fake=critereon(disc_fake,torch.zeros_like(disc_fake))\n",
    "            lossD = (lossD_fake+lossD_real)/2\n",
    "            \n",
    "            disc.zero_grad()\n",
    "            lossD.backward(retain_graph=True)\n",
    "            opt_disc.step()\n",
    "            \n",
    "            output=disc(fake_img).reshape(-1)\n",
    "            lossG=critereon(output,torch.ones_like(output))\n",
    "            gen.zero_grad()\n",
    "            lossG.backward()\n",
    "            opt_gen.step()\n",
    "            \n",
    "            if(batch_index%100==0):\n",
    "                print(f'[{epoch}/{num_epochs}--Loss(D):{lossD:.4f}--Loss(G):{lossG:.4f}')\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise)\n",
    "                img_grid_fake=torchvision.utils.make_grid(fake[:32],normalize=True)\n",
    "                img_grid_real=torchvision.utils.make_grid(real[:32],normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Fake img1\",img_grid_fake,global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Real img1\",img_grid_real,global_step=step\n",
    "                )\n",
    "\n",
    "            step+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95fc7375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'mainwrapper' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'mainwrapper' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# suppose we have 3 gpus\u001b[39;00m\n\u001b[1;32m      3\u001b[0m world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmainwrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:240\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    236\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    238\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m start_method)\n\u001b[1;32m    239\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:149\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    142\u001b[0m             (error_index, name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    147\u001b[0m         )\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    150\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    151\u001b[0m             (error_index, exitcode),\n\u001b[1;32m    152\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    153\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    154\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode\n\u001b[1;32m    155\u001b[0m         )\n\u001b[1;32m    157\u001b[0m original_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_queues[error_index]\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    158\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "import torch.multiprocessing as mp\n",
    "if __name__ == '__main__':\n",
    "    # suppose we have 3 gpus\n",
    "    world_size = 2\n",
    "    mp.spawn(\n",
    "        mainwrapper,\n",
    "        args=(world_size),\n",
    "        nprocs=world_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc612198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ef338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
